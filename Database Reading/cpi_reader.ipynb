{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "file_path = '640107.xlsx'\n",
    "categories = ['Lamb and goat',\n",
    "              'Wine',\n",
    "              'Food additives and condiments',\n",
    "              'Other meats',\n",
    "              'Garments for men',\n",
    "              'Cheese',\n",
    "              'Garments',\n",
    "              'Bread',\n",
    "              'Fruit',\n",
    "              'Footwear for men',\n",
    "              'Ice cream and other dairy products',\n",
    "              'Meals out and take away foods',\n",
    "              'Poultry',\n",
    "              'Restaurant meals',\n",
    "              'Glassware, tableware and household utensils',\n",
    "              'Garments for women',\n",
    "              'Other non-durable household products',\n",
    "              'Beer',\n",
    "              'Eggs',\n",
    "              'Oils and fats',\n",
    "              'Waters, soft drinks and juices',\n",
    "              'Other food products n.e.c.',\n",
    "              'Food products n.e.c.',\n",
    "              'Footwear for women',\n",
    "              'Meat and seafoods',\n",
    "              'Snacks and confectionery',\n",
    "              'Beef and veal',\n",
    "              'Take away and fast foods',\n",
    "              'Other cereal products',\n",
    "              'Cakes and biscuits',\n",
    "              'Coffee, tea and cocoa',\n",
    "              'Jams, honey and spreads',\n",
    "              'Books',\n",
    "              'Dairy and related products',\n",
    "              'Tobacco',\n",
    "              'Alcohol and tobacco',\n",
    "              'Pork',\n",
    "              'Garments for infants and children',\n",
    "              'Clothing and footwear',\n",
    "              'Bread and cereal products',\n",
    "              'Personal care products',\n",
    "              'Breakfast cereals',\n",
    "              'Fish and other seafood',\n",
    "              'Non-alcoholic beverages',\n",
    "              'Spirits',\n",
    "              'Non-durable household products',\n",
    "              'Footwear for infants and children',\n",
    "              'Cleaning and maintenance products',\n",
    "              'Newspapers, books and stationery',\n",
    "              'Milk',\n",
    "              'Household appliances, utensils and tools',\n",
    "              'Newspapers, magazines and stationery',\n",
    "              'Vegetables',\n",
    "              'Footwear',\n",
    "              'Alcoholic beverages',\n",
    "              'Fruit and vegetables',\n",
    "              'Furniture']\n",
    "\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheet_names = xls.sheet_names[2:-1]  # skip the first 2 sheets and the last one\n",
    "\n",
    "\n",
    "# Add first sheet manually\n",
    "combined_df = pd.read_excel(xls, xls.sheet_names[1])\n",
    "# Read each sheet and concatenate it horizontally to the combined DataFrame\n",
    "for sheet_name in sheet_names:\n",
    "    sheet_df = pd.read_excel(xls, sheet_name)\n",
    "    sheet_df = sheet_df.drop(sheet_df.columns[0], axis=1)\n",
    "    combined_df = pd.concat([combined_df, sheet_df], axis=1)\n",
    "\n",
    "combined_df.iloc[0] = combined_df.columns\n",
    "combined_df = combined_df.drop([2,3,4,5,6,7,8], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_row = combined_df.iloc[0]\n",
    "\n",
    "# Split the first row into three separate values using ';'\n",
    "new_header = header_row.str.split(';').tolist()\n",
    "new_header[0] = ['Date', np.NaN, np.NaN]\n",
    "for i in range(1,len(new_header)):\n",
    "    new_header[i] = new_header[i][1:3]\n",
    "    for j in range(2):\n",
    "        new_header[i][j] = new_header[i][j].strip()\n",
    "new_header = list(map(list, zip(*new_header)))\n",
    "new_header = pd.DataFrame(new_header)\n",
    "new_header = new_header.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/35fcv65d227brqg7pq_rvs_40000gn/T/ipykernel_5035/4084929838.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with the split values as the first row\n",
    "combined_df = combined_df.drop([0,1],axis=0)\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "combined_df.columns = new_header.columns\n",
    "combined_df = pd.concat([new_header, combined_df], axis=0, ignore_index=True)\n",
    "combined_df.columns = combined_df.iloc[0]\n",
    "combined_df=combined_df.drop([0], axis = 0)\n",
    "\n",
    "filtered_df = combined_df[categories + [\"Date\"]]\n",
    "filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
    "cols = ['Date'] + [col for col in filtered_df if col != 'Date']\n",
    "filtered_df = filtered_df[cols]\n",
    "\n",
    "transposed_df = filtered_df.T\n",
    "transposed_df = transposed_df.reset_index()\n",
    "dates = list(transposed_df.iloc[0][2:])\n",
    "transposed_df.columns = ['Product','City'] + dates\n",
    "transposed_df = transposed_df.drop([0])\n",
    "\n",
    "df_melted = transposed_df.melt(id_vars=['Product', 'City'], \n",
    "                    value_vars=dates,\n",
    "                    var_name='Date', value_name='Index Value')\n",
    "\n",
    "#df_melted[\"% Change\"] = df_melted['Index Value'].pct_change() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1453140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MySQL database configuration\n",
    "db_config = {\n",
    "    \"host\": \"fit3162.mysql.database.azure.com\",\n",
    "    \"user\": \"fit3162\",\n",
    "    \"password\": \"Consumercare123!\",\n",
    "    \"database\": \"fit3162\",\n",
    "    \"port\": 3306\n",
    "}\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f\"mysql+pymysql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\")\n",
    "\n",
    "# Get the table name\n",
    "table_name = 'cpi_data'\n",
    "\n",
    "# Create the table based on the dataframe structure\n",
    "df_melted.head(0).to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Insert the dataframe records into the table (replace if it exists)\n",
    "df_melted.to_sql(name=table_name, con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
